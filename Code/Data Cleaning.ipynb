{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import nltk\n",
    "import string\n",
    "import os\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from ggplot import *\n",
    "from nltk.corpus import stopwords\n",
    "from nltk import PorterStemmer\n",
    "from nltk.stem.snowball import SnowballStemmer\n",
    "stemmer = SnowballStemmer(\"english\")\n",
    "from nltk.stem import WordNetLemmatizer\n",
    "wordnet_lemmatizer = WordNetLemmatizer()\n",
    "from nltk.corpus import stopwords\n",
    "import re\n",
    "from collections import Counter\n",
    "import digify\n",
    "import regex"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#All classes\n",
    "class BaseReplacer:\n",
    "    def __init__(self, pattern_replace_pair_list=[]):\n",
    "        self.pattern_replace_pair_list = pattern_replace_pair_list\n",
    "    def transform(self, text):\n",
    "        for pattern, replace in self.pattern_replace_pair_list:\n",
    "            try:\n",
    "                text = regex.sub(pattern, replace, text)\n",
    "            except:\n",
    "                pass\n",
    "        return regex.sub(r\"\\s+\", \" \", text).strip()\n",
    "\n",
    "\n",
    "    \n",
    "class UnitConverter(BaseReplacer):\n",
    "    \"\"\"\n",
    "    shadeMature height: 36 in. - 48 in.Mature width\n",
    "    PUT one UnitConverter before LowerUpperCaseSplitter\n",
    "    \"\"\"\n",
    "    def __init__(self):\n",
    "        self.pattern_replace_pair_list = [\n",
    "            (r\"([0-9]+)( *)(inches|inch|in|in.|')\\.?\", r\"\\1 in. \"),\n",
    "            (r\"([0-9]+)( *)(pounds|pound|lbs|lb|lb.)\\.?\", r\"\\1 lb. \"),\n",
    "            (r\"([0-9]+)( *)(foot|feet|ft|ft.|'')\\.?\", r\"\\1 ft. \"),\n",
    "            (r\"([0-9]+)( *)(square|sq|sq.) ?\\.?(inches|inch|in|in.|')\\.?\", r\"\\1 sq.in. \"),\n",
    "            (r\"([0-9]+)( *)(square|sq|sq.) ?\\.?(feet|foot|ft|ft.|'')\\.?\", r\"\\1 sq.ft. \"),\n",
    "            (r\"([0-9]+)( *)(cubic|cu|cu.) ?\\.?(inches|inch|in|in.|')\\.?\", r\"\\1 cu.in. \"),\n",
    "            (r\"([0-9]+)( *)(cubic|cu|cu.) ?\\.?(feet|foot|ft|ft.|'')\\.?\", r\"\\1 cu.ft. \"),\n",
    "            (r\"([0-9]+)( *)(gallons|gallon|gal)\\.?\", r\"\\1 gal. \"),\n",
    "            (r\"([0-9]+)( *)(ounces|ounce|oz)\\.?\", r\"\\1 oz. \"),\n",
    "            (r\"([0-9]+)( *)(centimeters|cm)\\.?\", r\"\\1 cm. \"),\n",
    "            (r\"([0-9]+)( *)(milimeters|mm)\\.?\", r\"\\1 mm. \"),\n",
    "            (r\"([0-9]+)( *)(minutes|minute)\\.?\", r\"\\1 min. \"),\n",
    "            (r\"([0-9]+)( *)(Â°|degrees|degree)\\.?\", r\"\\1 deg. \"),\n",
    "            (r\"([0-9]+)( *)(v|volts|volt)\\.?\", r\"\\1 volt. \"),\n",
    "            (r\"([0-9]+)( *)(wattage|watts|watt)\\.?\", r\"\\1 watt. \"),\n",
    "            (r\"([0-9]+)( *)(amperes|ampere|amps|amp)\\.?\", r\"\\1 amp. \"),\n",
    "            (r\"([0-9]+)( *)(qquart|quart)\\.?\", r\"\\1 qt. \"),\n",
    "            (r\"([0-9]+)( *)(hours|hour|hrs.)\\.?\", r\"\\1 hr \"),\n",
    "            (r\"([0-9]+)( *)(gallons per minute|gallon per minute|gal per minute|gallons/min.|gallons/min)\\.?\", r\"\\1 gal. per min. \"),\n",
    "            (r\"([0-9]+)( *)(gallons per hour|gallon per hour|gal per hour|gallons/hour|gallons/hr)\\.?\", r\"\\1 gal. per hr \"),\n",
    "        ]\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#Extra Functions\n",
    "def remove_commas_and_quotes(mystring):\n",
    "    return re.sub(r'(?:(\\d+?),)',r'\\1',mystring)\n",
    "\n",
    "def hasNumbers(inputString):\n",
    "    return any(char.isdigit() for char in inputString)\n",
    "\n",
    "def lastlower(inputString):\n",
    "    pos=-1\n",
    "    for char in range(0,len(inputString)-1):\n",
    "        if inputString[char].islower() and inputString[char+1].isdigit():\n",
    "            pos=char\n",
    "    return pos\n",
    "\n",
    "def remove_puncs(word):\n",
    "    if hasNumbers(word):\n",
    "        p = re.compile(\"[^a-zA-Z0-9\\.\\-\\/\\,]\")\n",
    "        return p.sub(\" \", word)\n",
    "    else:\n",
    "        p = re.compile(\"[^a-zA-Z0-9]\")\n",
    "        return p.sub(\" \", word)\n",
    "    \n",
    "def splitdigits(word):\n",
    "    if lastlower(word)==-1:\n",
    "        return word\n",
    "    else:\n",
    "        return word[0:lastlower(word)+1]+\" \"+word[lastlower(word)+1:len(word)]\n",
    "        \n",
    "\n",
    "def di_digify(words):\n",
    "    try:\n",
    "        digify.spelled_num_to_digits(words)\n",
    "        return digify.spelled_num_to_digits(words)\n",
    "    except:\n",
    "        return words\n",
    "\n",
    "def digify_check(word):\n",
    "     try:\n",
    "        digify.spelled_num_to_digits(word)\n",
    "        return 1\n",
    "     except:\n",
    "        return 0\n",
    "\n",
    "def digitconverter(inputstr):\n",
    "    words = inputstr.split()\n",
    "    digit_words=[]\n",
    "    words_mod=[]           \n",
    "    for i in range(0,len(words)):\n",
    "        digit_words.append(digify_check(words[i]))\n",
    "\n",
    "    i=0\n",
    "    while i<len(words)-1:\n",
    "        if digit_words[i]+digit_words[i+1]==2:\n",
    "            words_mod.append(digify.spelled_num_to_digits(words[i]+\" \"+words[i+1]))\n",
    "            i=i+2\n",
    "        else:\n",
    "            words_mod.append(words[i])\n",
    "            i=i+1\n",
    "    if digify_check(words[len(words)-1])==0:\n",
    "        words_mod.append(words[len(words)-1])\n",
    "    digit_words=[]\n",
    "\n",
    "    for i in range(0,len(words_mod)):\n",
    "        digit_words.append(str(di_digify(str(words_mod[i]))))\n",
    "    return(' '.join(digit_words))\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#Load files\n",
    "product=pd.read_csv(\"train.csv\")\n",
    "description=pd.read_csv(\"product_descriptions.csv\")\n",
    "#product_desc=pd.merge(product, description)\n",
    "product_desc=product.copy()\n",
    "attributes=pd.read_csv(\"attributes.csv\")\n",
    "attributes=attributes.dropna()\n",
    "#product_desc.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#Extract brand and color\n",
    "attributes['name'] = attributes['name'].str.lower()\n",
    "brand = attributes[attributes['name'] ==\"mfg brand name\"]\n",
    "brand=brand.rename(columns={\"value\": \"product_brand\"})\n",
    "brand.drop('name', axis=1, inplace=True)\n",
    "color_columns = [\"product_color\", \"color family\", \"color/finish\", \"color/finish family\"]\n",
    "color = attributes[attributes['name'].isin(color_columns)][[\"product_uid\", \"value\"]].rename(columns={\"value\": \"product_color\"})\n",
    "color = color.dropna()\n",
    "agg_color = lambda x: \" \".join(list(set(x[\"product_color\"])))\n",
    "color = color.groupby(\"product_uid\").apply(agg_color)\n",
    "color = color.reset_index(name=\"product_color\")\n",
    "color[\"product_color\"] = color[\"product_color\"].values.astype(str)\n",
    "description = pd.merge(description, brand, on=\"product_uid\", how=\"left\")\n",
    "description = pd.merge(description, color, on=\"product_uid\", how=\"left\")\n",
    "description[\"product_brand\"] = description[\"product_brand\"].astype(str)\n",
    "description[\"product_color\"] = description[\"product_color\"].astype(str)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "attributes[\"product_uid\"] = attributes[\"product_uid\"].astype(str)\n",
    "attributes[\"product_attribute_concat\"]=attributes[\"name\"]+\" : \"+attributes[\"value\"]\n",
    "attr_concat=attributes.groupby('product_uid')['product_attribute_concat'].apply(' | '.join).reset_index()\n",
    "attr_concat[\"product_uid\"] = attr_concat[\"product_uid\"].astype(float)\n",
    "attr_concat[\"product_uid\"] = attr_concat[\"product_uid\"].astype(int)\n",
    "description = pd.merge(description, attr_concat, on=\"product_uid\", how=\"left\")\n",
    "description[\"product_attribute_concat\"] = description[\"product_attribute_concat\"].astype(str)\n",
    "#description.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#Removing comma from digits\n",
    "product_desc['product_title'] = product_desc['product_title'].apply(lambda x:  \" \".join\\\n",
    "                                                                ([remove_commas_and_quotes(word) for word in x.split(\" \")]))\n",
    "product_desc['search_term'] = product_desc['search_term'].apply(lambda x:  \" \".join\\\n",
    "                                                                ([remove_commas_and_quotes(word) for word in x.split(\" \")]))\n",
    "description['product_brand'] = description['product_brand'].apply(lambda x:  \" \".join\\\n",
    "                                                                ([remove_commas_and_quotes(word) for word in x.split(\" \")]))\n",
    "description['product_color'] = description['product_color'].apply(lambda x:  \" \".join\\\n",
    "                                                                ([remove_commas_and_quotes(word) for word in x.split(\" \")]))\n",
    "\n",
    "description['product_description'] = description['product_description'].apply(lambda x:  \" \".join\\\n",
    "                                                                ([remove_commas_and_quotes(word) for word in x.split(\" \")]))\n",
    "\n",
    "description['product_attribute_concat'] = description['product_attribute_concat'].apply(lambda x:  \" \".join\\\n",
    "                                                                ([remove_commas_and_quotes(word) for word in x.split(\" \")]))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#Removing punctuations\n",
    "product_desc['product_title'] = product_desc['product_title'].apply\\\n",
    "(lambda x:  \" \".join([remove_puncs(word) for word in x.split(\" \")]))\n",
    "product_desc['search_term'] = product_desc['search_term'].apply\\\n",
    "(lambda x:  \" \".join([remove_puncs(word) for word in x.split(\" \")]))\n",
    "description['product_brand'] = description['product_brand'].apply\\\n",
    "(lambda x:  \" \".join([remove_puncs(word) for word in x.split(\" \")]))\n",
    "description['product_color'] = description['product_color'].apply\\\n",
    "(lambda x:  \" \".join([remove_puncs(word) for word in x.split(\" \")]))\n",
    "description['product_description'] = description['product_description'].apply\\\n",
    "(lambda x:  \" \".join([remove_puncs(word) for word in x.split(\" \")]))\n",
    "description['product_attribute_concat'] = description['product_attribute_concat'].apply\\\n",
    "(lambda x:  \" \".join([remove_puncs(word) for word in x.split(\" \")]))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#Seperate using caps\n",
    "\n",
    "#splitting by case\n",
    "product_desc['product_title']= product_desc['product_title'].apply\\\n",
    "(lambda x:  ' '.join([str(elem) for elem in re.split(r'([A-Z][a-zA-Z]+)',x)]))\n",
    "\n",
    "product_desc['search_term']= product_desc['search_term'].apply\\\n",
    "(lambda x:  ' '.join([str(elem) for elem in re.split(r'([A-Z][a-zA-Z]+)',x)]))\n",
    "\n",
    "description['product_brand']= description['product_brand'].apply\\\n",
    "(lambda x:  ' '.join([str(elem) for elem in re.split(r'([A-Z][a-zA-Z]+)',x)]))\n",
    "\n",
    "description['product_color']= description['product_color'].apply\\\n",
    "(lambda x:  ' '.join([str(elem) for elem in re.split(r'([A-Z][a-zA-Z]+)',x)]))\n",
    "\n",
    "description['product_description']= description['product_description'].apply\\\n",
    "(lambda x:  ' '.join([str(elem) for elem in re.split(r'([A-Z][a-zA-Z]+)',x)]))\n",
    "\n",
    "description['product_attribute_concat']= description['product_attribute_concat'].apply\\\n",
    "(lambda x:  ' '.join([str(elem) for elem in re.split(r'([A-Z][a-zA-Z]+)',x)]))\n",
    "\n",
    "#splitting digits and alphabets\n",
    "\n",
    "\n",
    "product_desc['product_title']= product_desc['product_title'].apply\\\n",
    "(lambda x:  \" \".join([splitdigits(word) for word in x.split(\" \")]))\n",
    "\n",
    "product_desc['search_term']= product_desc['search_term'].apply\\\n",
    "(lambda x:  \" \".join([splitdigits(word) for word in x.split(\" \")]))\n",
    "\n",
    "description['product_brand']= description['product_brand'].apply\\\n",
    "(lambda x:  \" \".join([splitdigits(word) for word in x.split(\" \")]))\n",
    "\n",
    "description['product_color']= description['product_color'].apply\\\n",
    "(lambda x:  \" \".join([splitdigits(word) for word in x.split(\" \")]))\n",
    "\n",
    "description['product_description']= description['product_description'].apply\\\n",
    "(lambda x:  \" \".join([splitdigits(word) for word in x.split(\" \")]))\n",
    "\n",
    "description['product_attribute_concat']= description['product_attribute_concat'].apply\\\n",
    "(lambda x:  \" \".join([splitdigits(word) for word in x.split(\" \")]))\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#convert to lower\n",
    "product_desc['product_title']=product_desc['product_title'].str.lower()\n",
    "product_desc['search_term']=product_desc['search_term'].str.lower()\n",
    "description['product_brand']=description['product_brand'].str.lower()\n",
    "description['product_color']=description['product_color'].str.lower()\n",
    "description['product_description']=description['product_description'].str.lower()\n",
    "description['product_attribute_concat']=description['product_attribute_concat'].str.lower()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#Spell checker functions\n",
    "spell_df = description\n",
    "spell_df['constant']='group'\n",
    "combine = spell_df.groupby('constant')['product_description'].apply(' '.join).reset_index()\n",
    "concat=re.findall(r'\\w+',combine['product_description'][0])\n",
    "\n",
    "\n",
    "def words(text): return re.findall(r'\\w+', text.lower())\n",
    "\n",
    "WORDS = Counter(concat)\n",
    "\n",
    "def P(word, N=sum(WORDS.values())): \n",
    "    \"Probability of `word`.\"\n",
    "    return WORDS[word] / N\n",
    "\n",
    "def correction(word): \n",
    "    \"Most probable spelling correction for word.\"\n",
    "    return max(candidates(word), key=P)\n",
    "\n",
    "def candidates(word): \n",
    "    \"Generate possible spelling corrections for word.\"\n",
    "    return (known([word]) or known(edits1(word)) or known(edits2(word)) or [word])\n",
    "\n",
    "def known(words): \n",
    "    \"The subset of `words` that appear in the dictionary of WORDS.\"\n",
    "    return set(w for w in words if w in WORDS)\n",
    "\n",
    "def edits1(word):\n",
    "    \"All edits that are one edit away from `word`.\"\n",
    "    letters    = 'abcdefghijklmnopqrstuvwxyz'\n",
    "    splits     = [(word[:i], word[i:])    for i in range(len(word) + 1)]\n",
    "    deletes    = [L + R[1:]               for L, R in splits if R]\n",
    "    transposes = [L + R[1] + R[0] + R[2:] for L, R in splits if len(R)>1]\n",
    "    replaces   = [L + c + R[1:]           for L, R in splits if R for c in letters]\n",
    "    inserts    = [L + c + R               for L, R in splits for c in letters]\n",
    "    return set(deletes + transposes + replaces + inserts)\n",
    "\n",
    "def edits2(word): \n",
    "    \"All edits that are two edits away from `word`.\"\n",
    "    return (e2 for e1 in edits1(word) for e2 in edits1(e1))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#Spell checker\n",
    "product_desc['product_title'] = product_desc['product_title'].apply\\\n",
    "(lambda x:  \" \".join([correction(word) for word in x.split(\" \")]))\n",
    "product_desc['search_term'] = product_desc['search_term'].apply\\\n",
    "(lambda x:  \" \".join([correction(word) for word in x.split(\" \")]))\n",
    "description['product_brand'] = description['product_brand'].apply\\\n",
    "(lambda x:  \" \".join([correction(word) for word in x.split(\" \")]))\n",
    "description['product_color'] = description['product_color'].apply\\\n",
    "(lambda x:  \" \".join([correction(word) for word in x.split(\" \")]))\n",
    "description['product_description'] = description['product_description'].apply\\\n",
    "(lambda x:  \" \".join([correction(word) for word in x.split(\" \")]))\n",
    "description['product_attribute_concat'] = description['product_attribute_concat'].apply\\\n",
    "(lambda x:  \" \".join([correction(word) for word in x.split(\" \")]))\n",
    "description.drop('constant', axis=1, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#Removing stop words\n",
    "stop = stopwords.words(\"english\")\n",
    "product_desc['product_title'] = product_desc['product_title'].apply\\\n",
    "(lambda x:  \" \".join([word for word in x.split(\" \") if word not in stop]))\n",
    "product_desc['search_term'] = product_desc['search_term'].apply\\\n",
    "(lambda x:  \" \".join([word for word in x.split(\" \") if word not in stop]))\n",
    "description['product_brand'] = description['product_brand'].apply\\\n",
    "(lambda x:  \" \".join([word for word in x.split(\" \") if word not in stop]))\n",
    "description['product_color'] = description['product_color'].apply\\\n",
    "(lambda x:  \" \".join([word for word in x.split(\" \") if word not in stop]))\n",
    "description['product_description'] = description['product_description'].apply\\\n",
    "(lambda x:  \" \".join([word for word in x.split(\" \") if word not in stop]))\n",
    "description['product_attribute_concat'] = description['product_attribute_concat'].apply\\\n",
    "(lambda x:  \" \".join([word for word in x.split(\" \") if word not in stop]))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#Unit converter\n",
    "product_desc['product_title'] = product_desc['product_title'].apply(lambda x: UnitConverter().transform(x))\n",
    "product_desc['search_term'] = product_desc['search_term'].apply(lambda x: UnitConverter().transform(x))\n",
    "description['product_brand'] = description['product_brand'].apply(lambda x: UnitConverter().transform(x))\n",
    "description['product_color'] = description['product_color'].apply(lambda x: UnitConverter().transform(x))\n",
    "description['product_description'] = description['product_description'].apply(lambda x: UnitConverter().transform(x))\n",
    "description['product_attribute_concat'] = description['product_attribute_concat'].apply(lambda x: UnitConverter().transform(x))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#Lemmatization and stemming\n",
    "product_desc['product_title'] = product_desc['product_title'].apply(lambda x:  \" \".join([wordnet_lemmatizer.lemmatize(str(word))\\\n",
    "                                                                                         for word in x.split(\" \")]))\n",
    "#product_desc['product_title'] = product_desc['product_title'].apply(lambda x:  \" \".join([stemmer.stem(word)\\\n",
    "#                                                                                         for word in x.split(\" \")]))\n",
    "product_desc['search_term'] = product_desc['search_term'].apply(lambda x:  \" \".join([wordnet_lemmatizer.lemmatize(word)\\\n",
    "                                                                                     for word in x.split(\" \")]))\n",
    "#product_desc['search_term'] = product_desc['search_term'].apply(lambda x:  \" \".join([stemmer.stem(word)\\\n",
    "#                                                                                     for word in x.split(\" \")]))\n",
    "description['product_brand'] = description['product_brand'].apply(lambda x:  \" \".join([wordnet_lemmatizer.lemmatize(word) \\\n",
    "                                                                                         for word in x.split(\" \")]))\n",
    "#description['product_brand'] = description['product_brand'].apply(lambda x:  \" \".join([stemmer.stem(word)\\\n",
    "#                                                                                         for word in x.split(\" \")]))\n",
    "description['product_color'] = description['product_color'].apply(lambda x:  \" \".join([wordnet_lemmatizer.lemmatize(word) \\\n",
    "                                                                                         for word in x.split(\" \")]))\n",
    "#description['product_color'] = description['product_color'].apply(lambda x:  \" \".join([stemmer.stem(word)\\\n",
    "#                                                                                         for word in x.split(\" \")]))\n",
    "\n",
    "description['product_description'] = description['product_description'].apply\\\n",
    "(lambda x:  \" \".join([wordnet_lemmatizer.lemmatize(word) for word in x.split(\" \")]))\n",
    "#description['product_description'] = description['product_description'].apply\\\n",
    "#(lambda x:  \" \".join([stemmer.stem(word) for word in x.split(\" \")]))\n",
    "\n",
    "description['product_attribute_concat'] = description['product_attribute_concat'].apply\\\n",
    "(lambda x:  \" \".join([wordnet_lemmatizer.lemmatize(word) for word in x.split(\" \")]))\n",
    "#description['product_attribute_concat'] = description['product_attribute_concat'].apply\\\n",
    "#(lambda x:  \" \".join([stemmer.stem(word) for word in x.split(\" \")]))\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "product_desc['product_title'] = product_desc['product_title'].str.replace(' x ','x')\n",
    "product_desc['search_term']=product_desc['search_term'].str.replace(' x ','x')\n",
    "description['product_brand']=description['product_brand'].str.replace(' x ','x')\n",
    "description['product_color']=description['product_color'].str.replace(' x ','x')\n",
    "description['product_description']=description['product_description'].str.replace(' x ','x')\n",
    "description['product_attribute_concat']=description['product_attribute_concat'].replace(' x ','x')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "product_desc.to_csv(\"product_train_lemma.csv\",sep=\",\",index=False)\n",
    "description.to_csv(\"description_cleaned_lemma.csv\",sep=\",\",index=False)"
   ]
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python [conda root]",
   "language": "python",
   "name": "conda-root-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
